{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNRj8ORBWGPwFLkS043GCH8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shayankr/AI_and_ComputerVision/blob/master/CNN_Model_Dogs_vs_Cats.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kaggle Dataset link: https://www.kaggle.com/competitions/dogs-vs-cats/data"
      ],
      "metadata": {
        "id": "lEnqS5mg3vzf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PzDr1gdfCuUk"
      },
      "outputs": [],
      "source": [
        "import tensorflow\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAghp87SDvaA",
        "outputId": "48a84860-ddcb-4a90-ca4e-666736d423e9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Some Necessary Packages/Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import os\n",
        "import shutil"
      ],
      "metadata": {
        "id": "_5WYbkNKDxjN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now kaggle"
      ],
      "metadata": {
        "id": "rLfhlC6p2bQJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "Qd5FLhZJ2iQl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /root/.kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnRPY2iZ2x3P",
        "outputId": "bdbaf9ab-259e-4a27-c282-d6ec24fd140c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls ~/.kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbNryyr623De",
        "outputId": "a393b91c-faf6-4a0e-d4df-14b86e450d07"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3s6VV06266A",
        "outputId": "cddcda80-e64c-43cb-a9d7-fb82985555d4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "ApGTHHkE2_p7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c dogs-vs-cats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-21G0poZ3CoB",
        "outputId": "7369958e-fd8a-41d7-f096-ecb773b6c138"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dogs-vs-cats.zip to /content\n",
            " 99% 801M/812M [00:17<00:00, 71.3MB/s]\n",
            "100% 812M/812M [00:17<00:00, 47.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -u dogs-vs-cats.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_VN6U993Wwe",
        "outputId": "88aa0bb4-ec9a-407e-f5fa-fbdaacc90c24"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  dogs-vs-cats.zip\n",
            "  inflating: sampleSubmission.csv    \n",
            "  inflating: test1.zip               \n",
            "  inflating: train.zip               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, Unzip train data only\n",
        "!unzip -u -q train.zip"
      ],
      "metadata": {
        "id": "7YpLDGUQ3cG5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(os.listdir(\"train\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFSwJkO43myA",
        "outputId": "41d720cc-5c7c-47ff-fdbb-c4d7a18b51fb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf train_1\n",
        "!rm -rf train_1/cat\n",
        "!rm -rf train_1/dog"
      ],
      "metadata": {
        "id": "hiJv4qUC5SMv"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make one sepearte folder for train data and put then cat and dog images as a sepearte folder.\n",
        "os.mkdir(\"train1\")\n",
        "os.mkdir(\"train1/cat\")\n",
        "os.mkdir(\"train1/dog\")"
      ],
      "metadata": {
        "id": "mTiNn0Y231G0"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src_folder = \"train/\"\n",
        "cat_folder = \"train1/cat/\"\n",
        "dog_folder = \"train1/dog/\""
      ],
      "metadata": {
        "id": "ETKb0nHH4P5a"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now Fill cat and dog folder with cat and dog images respectively.\n",
        "for image_name in os.listdir(src_folder):\n",
        "  if \"cat\" in image_name:\n",
        "    shutil.copy(src_folder+image_name, cat_folder)\n",
        "  elif \"dog\" in image_name:\n",
        "    shutil.copy(src_folder+image_name, dog_folder)\n",
        "    "
      ],
      "metadata": {
        "id": "_0T1nMxl4cLs"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Image Data Generator\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "h4hnGnWM5gw4"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import load_img, array_to_img, img_to_array"
      ],
      "metadata": {
        "id": "zn-fUyrs5n7J"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idg = ImageDataGenerator(rescale=1/255.0, vertical_flip=True, horizontal_flip=True,\n",
        "                         zoom_range=0.2, rotation_range=45, validation_split=0.2)"
      ],
      "metadata": {
        "id": "TI-Ok3EZ56_J"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = idg.flow_from_directory(subset=\"training\", directory=\"train1\", batch_size=64, target_size=(150,150))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsLtV3Dg62FM",
        "outputId": "74ed15ed-9c09-4bbf-e21e-4b1376e82cde"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_generator = idg.flow_from_directory(subset=\"validation\", directory=\"train1\", batch_size=64, target_size=(150,150))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1j0aTQ2P77yt",
        "outputId": "e99890de-6f6f-4a45-e486-a9da00a0ee0c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi  # Check whether GPU is connected or not ,,,,, if not then change runtype to GPU or TPU for faster processing."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXvWd9LZ8T4c",
        "outputId": "5c4dcedb-f69b-48b0-852a-d2ab13c53a87"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Oct  6 20:58:20 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, Buuild NN/CNN Model"
      ],
      "metadata": {
        "id": "xpdSgu_28X4z"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Dense, Conv2D, MaxPooling2D\n",
        "from keras.activations import relu, softmax\n",
        "from keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import SGD"
      ],
      "metadata": {
        "id": "-7jJkvna8saJ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import activations\n",
        "model = Sequential()\n",
        "\n",
        "# 1st Chunk\n",
        "model.add(Conv2D(filters=32, kernel_size=(3,3), strides=(1,1), padding='valid', activation=relu,  \n",
        "                 input_shape=(150,150,3)))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid', ))\n",
        "\n",
        "# 2nd Chunk\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='valid', activation=relu,))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid', ))\n",
        "\n",
        "#150-3+1/1=148,148, 32\n",
        "\n",
        "#74,74,32\n",
        "\n",
        "#74-3+1/1 = 72,72 , 64\n",
        "\n",
        "#36,36,64\n",
        "\n",
        "#Apply Flattening\n",
        "model.add(Flatten())\n",
        "#36*36*64 = 1296*64 = 82944\n",
        "\n",
        "#model.add(Dense(1024, activation=softmax))\n",
        "#\n",
        "#model.add(Dense(128, activation=softmax))\n",
        "model.add(Dense(512, activation=softmax))\n",
        "#\n",
        "model.add(Dense(2, activation=softmax)) \n",
        "model.summary()\n",
        "#RGB\n",
        "# IN DNN we  have an option to intialize weights through algorithms do we have  same kind of  filtes in CNN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYor6iZ49b7c",
        "outputId": "387dc779-5cf9-4f1b-aad4-b1fa24e2bdc0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 72, 72, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 36, 36, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 82944)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               42467840  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 1026      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 42,488,258\n",
            "Trainable params: 42,488,258\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #(3,3) =9 random values \n",
        "# #32 filters\n",
        "# #32*9 = 288 *3 RGB\n",
        "# #288*3=864\n",
        "# #864+32(bias)=896\n",
        "\n",
        "# #we dont have any parmaters in max pooling , we dont\n",
        "\n",
        "# #64(filters)*9(random value)=576\n",
        "# #576*32(depth similar to 3 channel in  1st chunk)=18432\n",
        "\n",
        "# #18432+ 64 (bias) = 18496\n",
        "\n",
        "# #32\n",
        "# #Maxpooling to flatten\n",
        "# 36*36*64=82944\n",
        "# #flatten to  Dense\n",
        "# #82944 *2 +2 (bias) = 165890  #if directly last layer applied.\n",
        "\n",
        "#we dont know the number of images in batch ,None is like default place  holder\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Z59maH88Cp7a"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizers\n",
        "model.compile(optimizer=SGD(), loss=categorical_crossentropy, metrics=['acc'])"
      ],
      "metadata": {
        "id": "AgLirB4FEH5O"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_generator, epochs=20, validation_data=val_generator,) #GPU"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtK7Yaz8Eanf",
        "outputId": "243e0de7-e961-48cd-b876-db80240a2c9f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "313/313 [==============================] - 198s 603ms/step - loss: 0.6932 - acc: 0.4987 - val_loss: 0.6931 - val_acc: 0.5000\n",
            "Epoch 2/20\n",
            "313/313 [==============================] - 199s 636ms/step - loss: 0.6932 - acc: 0.4967 - val_loss: 0.6931 - val_acc: 0.5000\n",
            "Epoch 3/20\n",
            "313/313 [==============================] - 177s 567ms/step - loss: 0.6932 - acc: 0.5003 - val_loss: 0.6931 - val_acc: 0.5000\n",
            "Epoch 4/20\n",
            "313/313 [==============================] - 172s 549ms/step - loss: 0.6932 - acc: 0.4974 - val_loss: 0.6931 - val_acc: 0.5000\n",
            "Epoch 5/20\n",
            "313/313 [==============================] - 187s 597ms/step - loss: 0.6932 - acc: 0.5002 - val_loss: 0.6931 - val_acc: 0.5000\n",
            "Epoch 6/20\n",
            "313/313 [==============================] - 171s 546ms/step - loss: 0.6932 - acc: 0.4955 - val_loss: 0.6931 - val_acc: 0.5254\n",
            "Epoch 7/20\n",
            "313/313 [==============================] - 171s 547ms/step - loss: 0.6932 - acc: 0.5026 - val_loss: 0.6931 - val_acc: 0.5000\n",
            "Epoch 8/20\n",
            "313/313 [==============================] - 176s 564ms/step - loss: 0.6932 - acc: 0.5003 - val_loss: 0.6931 - val_acc: 0.5000\n",
            "Epoch 9/20\n",
            "313/313 [==============================] - 170s 542ms/step - loss: 0.6932 - acc: 0.4979 - val_loss: 0.6931 - val_acc: 0.5000\n",
            "Epoch 10/20\n",
            "313/313 [==============================] - 169s 541ms/step - loss: 0.6932 - acc: 0.4990 - val_loss: 0.6931 - val_acc: 0.5000\n",
            "Epoch 11/20\n",
            "313/313 [==============================] - 169s 541ms/step - loss: 0.6932 - acc: 0.4980 - val_loss: 0.6931 - val_acc: 0.5006\n",
            "Epoch 12/20\n",
            "313/313 [==============================] - 169s 540ms/step - loss: 0.6932 - acc: 0.4999 - val_loss: 0.6931 - val_acc: 0.5000\n",
            "Epoch 13/20\n",
            "313/313 [==============================] - 171s 546ms/step - loss: 0.6931 - acc: 0.5046 - val_loss: 0.6931 - val_acc: 0.5000\n",
            "Epoch 14/20\n",
            "313/313 [==============================] - 172s 551ms/step - loss: 0.6931 - acc: 0.5004 - val_loss: 0.6931 - val_acc: 0.5000\n",
            "Epoch 15/20\n",
            "313/313 [==============================] - 171s 546ms/step - loss: 0.6931 - acc: 0.5033 - val_loss: 0.6931 - val_acc: 0.5000\n",
            "Epoch 16/20\n",
            "313/313 [==============================] - 169s 541ms/step - loss: 0.6931 - acc: 0.4997 - val_loss: 0.6931 - val_acc: 0.5466\n",
            "Epoch 17/20\n",
            "313/313 [==============================] - 169s 542ms/step - loss: 0.6931 - acc: 0.5038 - val_loss: 0.6931 - val_acc: 0.5000\n",
            "Epoch 18/20\n",
            "313/313 [==============================] - 169s 540ms/step - loss: 0.6931 - acc: 0.5008 - val_loss: 0.6931 - val_acc: 0.5470\n",
            "Epoch 19/20\n",
            "313/313 [==============================] - 169s 541ms/step - loss: 0.6931 - acc: 0.5039 - val_loss: 0.6931 - val_acc: 0.5004\n",
            "Epoch 20/20\n",
            "313/313 [==============================] - 169s 540ms/step - loss: 0.6931 - acc: 0.5034 - val_loss: 0.6931 - val_acc: 0.5000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9b789b9e10>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#task\n",
        "\n",
        "# try to achieve accuracy of 70%"
      ],
      "metadata": {
        "id": "DFrBAVS-GK8l"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"CatVsDogCNN_07102022\")"
      ],
      "metadata": {
        "id": "2fzDNiilGNau"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can save tis model into Drive also. So that We can save permanently this model.\n",
        "# When need to load... we can import from drive folder/file."
      ],
      "metadata": {
        "id": "KXzDuJ7AGrCo"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator.class_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AusUPYLUGQRj",
        "outputId": "857466ce-71de-4552-ef8c-6972e990c933"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cat': 0, 'dog': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_generator.class_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQFDrKPHGlPh",
        "outputId": "acf3ac32-a76b-4f7c-9ffd-8bdc6ff5c15d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cat': 0, 'dog': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model"
      ],
      "metadata": {
        "id": "_Fq4ES1RGVR1"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2=load_model(filepath=\"CatVsDogCNN_07102022\")"
      ],
      "metadata": {
        "id": "QbT9uEmeGnD8"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvl_7P7xG3io",
        "outputId": "c0d62f63-f97a-47c0-880b-b8cda72b369b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 72, 72, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 36, 36, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 82944)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               42467840  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 1026      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 42,488,258\n",
            "Trainable params: 42,488,258\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r  model.zip  CatVsDogCNN_07102022"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyzoa4iIG5_r",
        "outputId": "dd024d56-4f23-4193-b559-e376a64d3320"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: CatVsDogCNN_07102022/ (stored 0%)\n",
            "  adding: CatVsDogCNN_07102022/assets/ (stored 0%)\n",
            "  adding: CatVsDogCNN_07102022/saved_model.pb (deflated 88%)\n",
            "  adding: CatVsDogCNN_07102022/variables/ (stored 0%)\n",
            "  adding: CatVsDogCNN_07102022/variables/variables.data-00000-of-00001 (deflated 8%)\n",
            "  adding: CatVsDogCNN_07102022/variables/variables.index (deflated 55%)\n",
            "  adding: CatVsDogCNN_07102022/keras_metadata.pb (deflated 90%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp model.zip /content/drive/MyDrive/\"Colab Notebooks\"\n",
        "#shutil.copy(\"model.zip\",\"/content/drive/MyDrive/'Colab Notebooks'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OYuuWkTTG-5w",
        "outputId": "58a86877-4479-4594-d796-8b06bac0c6a9"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"/content/drive/MyDrive/'Colab Notebooks'\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jVhJgLbWHOX",
        "outputId": "6c0a5fca-d2fe-458a-f12b-43d5a1896ec7"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9b789b9e10>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "help(model.history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5-QKgyGXpRM",
        "outputId": "e300823f-02db-4753-d810-46b32b7ab666"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on History in module keras.callbacks object:\n",
            "\n",
            "class History(Callback)\n",
            " |  Callback that records events into a `History` object.\n",
            " |  \n",
            " |  This callback is automatically applied to\n",
            " |  every Keras model. The `History` object\n",
            " |  gets returned by the `fit` method of models.\n",
            " |  \n",
            " |  Example:\n",
            " |  \n",
            " |  >>> model = tf.keras.models.Sequential([tf.keras.layers.Dense(10)])\n",
            " |  >>> model.compile(tf.keras.optimizers.SGD(), loss='mse')\n",
            " |  >>> history = model.fit(np.arange(100).reshape(5, 20), np.zeros(5),\n",
            " |  ...                     epochs=10)\n",
            " |  >>> print(history.params)\n",
            " |  {'verbose': 1, 'epochs': 10, 'steps': 1}\n",
            " |  >>> # check the keys of history object\n",
            " |  >>> print(history.history.keys())\n",
            " |  dict_keys(['loss'])\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      History\n",
            " |      Callback\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self)\n",
            " |      Initialize self.  See help(type(self)) for accurate signature.\n",
            " |  \n",
            " |  on_epoch_end(self, epoch, logs=None)\n",
            " |      Called at the end of an epoch.\n",
            " |      \n",
            " |      Subclasses should override for any actions to run. This function should only\n",
            " |      be called during TRAIN mode.\n",
            " |      \n",
            " |      Args:\n",
            " |          epoch: Integer, index of epoch.\n",
            " |          logs: Dict, metric results for this training epoch, and for the\n",
            " |            validation epoch if validation is performed. Validation result keys\n",
            " |            are prefixed with `val_`. For training epoch, the values of the\n",
            " |           `Model`'s metrics are returned. Example : `{'loss': 0.2, 'accuracy':\n",
            " |             0.7}`.\n",
            " |  \n",
            " |  on_train_begin(self, logs=None)\n",
            " |      Called at the beginning of training.\n",
            " |      \n",
            " |      Subclasses should override for any actions to run.\n",
            " |      \n",
            " |      Args:\n",
            " |          logs: Dict. Currently no data is passed to this argument for this method\n",
            " |            but that may change in the future.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from Callback:\n",
            " |  \n",
            " |  on_batch_begin(self, batch, logs=None)\n",
            " |      A backwards compatibility alias for `on_train_batch_begin`.\n",
            " |  \n",
            " |  on_batch_end(self, batch, logs=None)\n",
            " |      A backwards compatibility alias for `on_train_batch_end`.\n",
            " |  \n",
            " |  on_epoch_begin(self, epoch, logs=None)\n",
            " |      Called at the start of an epoch.\n",
            " |      \n",
            " |      Subclasses should override for any actions to run. This function should only\n",
            " |      be called during TRAIN mode.\n",
            " |      \n",
            " |      Args:\n",
            " |          epoch: Integer, index of epoch.\n",
            " |          logs: Dict. Currently no data is passed to this argument for this method\n",
            " |            but that may change in the future.\n",
            " |  \n",
            " |  on_predict_batch_begin(self, batch, logs=None)\n",
            " |      Called at the beginning of a batch in `predict` methods.\n",
            " |      \n",
            " |      Subclasses should override for any actions to run.\n",
            " |      \n",
            " |      Note that if the `steps_per_execution` argument to `compile` in\n",
            " |      `tf.keras.Model` is set to `N`, this method will only be called every `N`\n",
            " |      batches.\n",
            " |      \n",
            " |      Args:\n",
            " |          batch: Integer, index of batch within the current epoch.\n",
            " |          logs: Dict. Currently no data is passed to this argument for this method\n",
            " |            but that may change in the future.\n",
            " |  \n",
            " |  on_predict_batch_end(self, batch, logs=None)\n",
            " |      Called at the end of a batch in `predict` methods.\n",
            " |      \n",
            " |      Subclasses should override for any actions to run.\n",
            " |      \n",
            " |      Note that if the `steps_per_execution` argument to `compile` in\n",
            " |      `tf.keras.Model` is set to `N`, this method will only be called every `N`\n",
            " |      batches.\n",
            " |      \n",
            " |      Args:\n",
            " |          batch: Integer, index of batch within the current epoch.\n",
            " |          logs: Dict. Aggregated metric results up until this batch.\n",
            " |  \n",
            " |  on_predict_begin(self, logs=None)\n",
            " |      Called at the beginning of prediction.\n",
            " |      \n",
            " |      Subclasses should override for any actions to run.\n",
            " |      \n",
            " |      Args:\n",
            " |          logs: Dict. Currently no data is passed to this argument for this method\n",
            " |            but that may change in the future.\n",
            " |  \n",
            " |  on_predict_end(self, logs=None)\n",
            " |      Called at the end of prediction.\n",
            " |      \n",
            " |      Subclasses should override for any actions to run.\n",
            " |      \n",
            " |      Args:\n",
            " |          logs: Dict. Currently no data is passed to this argument for this method\n",
            " |            but that may change in the future.\n",
            " |  \n",
            " |  on_test_batch_begin(self, batch, logs=None)\n",
            " |      Called at the beginning of a batch in `evaluate` methods.\n",
            " |      \n",
            " |      Also called at the beginning of a validation batch in the `fit`\n",
            " |      methods, if validation data is provided.\n",
            " |      \n",
            " |      Subclasses should override for any actions to run.\n",
            " |      \n",
            " |      Note that if the `steps_per_execution` argument to `compile` in\n",
            " |      `tf.keras.Model` is set to `N`, this method will only be called every `N`\n",
            " |      batches.\n",
            " |      \n",
            " |      Args:\n",
            " |          batch: Integer, index of batch within the current epoch.\n",
            " |          logs: Dict. Currently no data is passed to this argument for this method\n",
            " |            but that may change in the future.\n",
            " |  \n",
            " |  on_test_batch_end(self, batch, logs=None)\n",
            " |      Called at the end of a batch in `evaluate` methods.\n",
            " |      \n",
            " |      Also called at the end of a validation batch in the `fit`\n",
            " |      methods, if validation data is provided.\n",
            " |      \n",
            " |      Subclasses should override for any actions to run.\n",
            " |      \n",
            " |      Note that if the `steps_per_execution` argument to `compile` in\n",
            " |      `tf.keras.Model` is set to `N`, this method will only be called every `N`\n",
            " |      batches.\n",
            " |      \n",
            " |      Args:\n",
            " |          batch: Integer, index of batch within the current epoch.\n",
            " |          logs: Dict. Aggregated metric results up until this batch.\n",
            " |  \n",
            " |  on_test_begin(self, logs=None)\n",
            " |      Called at the beginning of evaluation or validation.\n",
            " |      \n",
            " |      Subclasses should override for any actions to run.\n",
            " |      \n",
            " |      Args:\n",
            " |          logs: Dict. Currently no data is passed to this argument for this method\n",
            " |            but that may change in the future.\n",
            " |  \n",
            " |  on_test_end(self, logs=None)\n",
            " |      Called at the end of evaluation or validation.\n",
            " |      \n",
            " |      Subclasses should override for any actions to run.\n",
            " |      \n",
            " |      Args:\n",
            " |          logs: Dict. Currently the output of the last call to\n",
            " |            `on_test_batch_end()` is passed to this argument for this method\n",
            " |            but that may change in the future.\n",
            " |  \n",
            " |  on_train_batch_begin(self, batch, logs=None)\n",
            " |      Called at the beginning of a training batch in `fit` methods.\n",
            " |      \n",
            " |      Subclasses should override for any actions to run.\n",
            " |      \n",
            " |      Note that if the `steps_per_execution` argument to `compile` in\n",
            " |      `tf.keras.Model` is set to `N`, this method will only be called every `N`\n",
            " |      batches.\n",
            " |      \n",
            " |      Args:\n",
            " |          batch: Integer, index of batch within the current epoch.\n",
            " |          logs: Dict. Currently no data is passed to this argument for this method\n",
            " |            but that may change in the future.\n",
            " |  \n",
            " |  on_train_batch_end(self, batch, logs=None)\n",
            " |      Called at the end of a training batch in `fit` methods.\n",
            " |      \n",
            " |      Subclasses should override for any actions to run.\n",
            " |      \n",
            " |      Note that if the `steps_per_execution` argument to `compile` in\n",
            " |      `tf.keras.Model` is set to `N`, this method will only be called every `N`\n",
            " |      batches.\n",
            " |      \n",
            " |      Args:\n",
            " |          batch: Integer, index of batch within the current epoch.\n",
            " |          logs: Dict. Aggregated metric results up until this batch.\n",
            " |  \n",
            " |  on_train_end(self, logs=None)\n",
            " |      Called at the end of training.\n",
            " |      \n",
            " |      Subclasses should override for any actions to run.\n",
            " |      \n",
            " |      Args:\n",
            " |          logs: Dict. Currently the output of the last call to `on_epoch_end()`\n",
            " |            is passed to this argument for this method but that may change in\n",
            " |            the future.\n",
            " |  \n",
            " |  set_model(self, model)\n",
            " |  \n",
            " |  set_params(self, params)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from Callback:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#END"
      ],
      "metadata": {
        "id": "G5FMxEQYG8kj"
      },
      "execution_count": 57,
      "outputs": []
    }
  ]
}